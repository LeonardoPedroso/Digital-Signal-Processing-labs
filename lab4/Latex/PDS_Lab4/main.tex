\documentclass[a4paper, oneside, 11pt]{article}

\usepackage[english]{babel}
\usepackage[T1]{fontenc}

\usepackage[a4paper,top=2.5cm,bottom=2.5cm,left=2cm,right=2cm]{geometry}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[labelfont=bf]{caption}
\usepackage{subcaption}
\usepackage{comment}
\usepackage{lastpage}
\usepackage{siunitx}
\usepackage{csquotes}
\usepackage{amsfonts}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{indentfirst}

\allowdisplaybreaks

\pagestyle{fancy}
\fancyhf{}
\rhead{Anomaly detection}
\lhead{Digital Signal Processing}
\cfoot{Page  \thepage \hspace{1pt} of \pageref{LastPage}}
\setlength{\headheight}{14pt}

\begin{document}

\begin{titlepage}
	\begin{center}
		\begin{figure}[htb!]
			\centering
				\includegraphics[width=10cm]{figures/istlogo.jpg}
		\end{figure}
        
        \LARGE{\textbf{Instituto Superior Técnico}}\\
        \vspace{20pt}
        \Large{Integrated Masters in Aerospace Engineering}\\
        \vspace{10pt}
        \Large{Digital Signal Processing}\\
        \vspace{10pt}
        \Large{2\textsuperscript{nd} Semester 2020/2021}\\
            
        \vspace{40pt}
        \noindent\rule{15cm}{1pt}\\
        \Huge{\center \textbf{Laboratory 4}} 
        \par 
        \Huge{\center \textbf{Anomaly detection in energy time series data}}\\
        \noindent\rule{15cm}{1pt}\\
        
        \vspace{60pt}
        \large{\begin{tabular}{ll}
            \textbf{Group 40:} & \textbf{Professor:} \\
            89683, José Neves & Prof. Rita Cunha\\
            89691, Leonardo Pedroso \hspace{1cm} & \\
        \end{tabular}}
    
        \vspace{60pt}
        \large{\today}
	\end{center}
\end{titlepage}

\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{R1. Prediction}\label{sec:r1}

\subsection{R1.a) Long term prediction function}

To detect anomalies in energy production data, one can consider it to be given by the output of an autoregressive model (AR). The model considered is divided into two models, a long term model and a short term model. The long term model is given by
\begin{equation} \label{eq:long_term_pred}
    x(n) = a x(n-N) + r(n),
\end{equation}
where $x(n)$ is the produced energy signal, $a \in \mathbb{R}$ is a coefficient of the model, $N \in \mathbb{N}$ is a delay, and $r(n)$ is a residual. From a set of observations $x(n), \; n = 1, ..., M$ with $M \in \mathbb{Z}$, it is possible to obtain an estimate of $a$, $\hat{a}$, that fits $x(n)$ to the model in \eqref{eq:long_term_pred}. First, an energy criterion dependent on $a$ is defined as $E: \mathbb{R} \rightarrow \mathbb{R}$
\begin{equation} \label{eq:energy_long_term_0}
    E(a) = \sum_{i = N+1}^{M} r(i)^2 = \sum_{i = N+1}^{M} \left (x(i) - a x(i-N) \right)^2
\end{equation}
based on the residuals of the model. Defining the vectors
\begin{equation*}
    \mathbf{b} = \begin{bmatrix} x(N+1) \\ ... \\ x(M)\end{bmatrix}, \quad \mathbf{c} = \begin{bmatrix} x(1) \\ ... \\ x(M-N) \end{bmatrix},
\end{equation*}
one may rewrite \eqref{eq:energy_long_term_0} as
\begin{equation} \label{eq:energy_long_term}
    E(a) = \| \mathbf{b} - \mathbf{c} a \|^2,
\end{equation}
showing that the problem is a least-squares problem, whose solution is given by
\begin{equation} \label{eq:long_term_est}
    \hat{a} = \underset{a}{\operatorname{arg \; min}} \; E(a) = (\mathbf{c}^T \mathbf{c})^{-1} \mathbf{c}^T \mathbf{b} = \dfrac{\mathbf{c}^T \mathbf{b}}{\| \mathbf{c} \|}.
\end{equation}

From \eqref{eq:energy_long_term} and \eqref{eq:long_term_est}, a \texttt{MATLAB}{\texttrademark} function was written to return an estimate of $a$ and the corresponding residuals energy, called \texttt{ARmodelR1a.m}. This function receives a vector of observations of a given length and the value of $N$.

\subsection{R1.b) Test of the long term prediction function}

Using the previous \texttt{MATLAB}{\texttrademark} function, predictions of energy production data from a residential solar panel were obtained. These predictions, $\hat{x}(n)$, were obtained from data $x(n)$ as
\begin{equation}
    \hat{x}(n) = \hat{a} x(n-N),
\end{equation}
where $\hat{a}$ was obtained from \texttt{ARmodelR1a.m} and $N$ was chosen to be $N=96$, so that the predictions would be obtained from data from the previous day (the data is sampled at 15 minutes periods). In Fig. \ref{fig:R1b_x}, the training data and the obtained prediction are plotted. The corresponding residuals were plotted in Fig. \ref{fig:R1b_r}. It is possible to observe, from Figs. \ref{fig:R1b_x} and \ref{fig:R1b_r}, that the residuals of the predictions are not small for some days. However, it is considered that the prediction from the model is being well obtained.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/long_term_pred.pdf}
    \caption{Training data and prediction for the long term prediction model.}
    \label{fig:R1b_x}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/residuals.pdf}
    \caption{Residual corresponding to the previous long term prediction obtained.}
    \label{fig:R1b_r}
\end{figure}

\subsection{R1.c) Coefficient and energy of the residuals}

In order to obtain the previous predictions, an estimate of $a$ and the corresponding residuals energy were obtained. The results were
\begin{equation}
    \hat{a} \approx 0.9810, \quad E(\hat{a}) \approx 0.3478.
\end{equation}
From the value of $\hat{a}$, it is possible to observe that it is expected that the energy produced slightly decreases from day to day. This may due to the natural variation of sunlight across a season like summer or autumn. Regarding the value of $E(a)$, \textit{i.e.}, the sum of the squared errors, one can compute the root mean squared error. It yields $RMS = 0.0174$, which is about one order of magnitude below the order of magnitude of the data points, confirming that the fit is adequate.

\subsection{R1.d) Short term prediction function}

From the results already obtained, it is possible to obtain the coefficients of an autoregressive short term model of the residuals obtained with the long term model,
\begin{equation*}
    r(n) = x(n) - \hat{x}(n), \; n = N+1,...,M
\end{equation*}
The short term model is given by
\begin{equation*}
    r(n) = \sum_{k=1}^P d_k r(n-k) + e(n),
\end{equation*}
where $P\in \mathbb{N}$ is the number of previous samples of residuals to be considered, $d_1, ..., d_P$ are the coefficients, and $e(n)$ is the prediction error. Using a similar reason to the one of the long term prediction, an energy criterion dependent on the coefficients of the model is defined as $E_e: \mathbb{R}^P \rightarrow \mathbb{R}$
\begin{equation} \label{eq:energy_short_term_0}
    E_e(d_1,...,d_P) = \sum_{i=N+P+1}^M e(i)^2 = \sum_{i=N+P+1}^M \left (r(i) - \sum_{k=1}^P d_k r(i-k) \right)^2.
\end{equation}
Considering
\begin{equation*}
    \mathbf{d} = \begin{bmatrix} d_1 \\ d_2 \\ ... \\ d_P \end{bmatrix}, \quad A = \begin{bmatrix} r(N+P) & ... & r(N+1) \\
    r(N+P+1) & ... & r(N+2) \\
    & ... & \\
    r(M-1) & ... & r(M-P) \end{bmatrix}, \quad \mathbf{y} = \begin{bmatrix} r(N+P+1) \\ r(N+P+2) \\ ... \\ r(M) \end{bmatrix},
\end{equation*}
one may rewrite \eqref{eq:energy_short_term_0} as a least-squares problem,
\begin{equation} \label{eq:energy_short_term}
    E_e(\mathbf{d}) = \| \mathbf{y} - A \mathbf{d} \|^2,
\end{equation}
and, therefore, obtain estimates
\begin{equation} \label{eq:short_term_est}
    \hat{\mathbf{d}} = (A^T A)^{-1} A^T \mathbf{y}.
\end{equation}

From \eqref{eq:energy_short_term} and \eqref{eq:short_term_est}, a \texttt{MATLAB}{\texttrademark} function was written to return an estimate of $\mathbf{d}$ and the corresponding errors energy, called \texttt{ARmodelR1d.m}. This function receives a vector of observations of a given length and the value of $P$.

\subsection{R1.e) Test of the short term prediction function}

Using the previous \texttt{MATLAB}{\texttrademark} function, predictions of the residuals were obtained. These predictions, $\hat{r}(n)$, were obtained from data $r(n)$ as
\begin{equation}
    \hat{r}(n) = \sum_{k=1}^P \hat{d}_k r(n-k),
\end{equation}
where $\hat{\mathbf{d}} = d_1, ..., d_P$ was obtained from \texttt{ARmodelR1d.m} and $P$ was chosen to be $N=6$. In Fig. \ref{fig:residuals_prediction}, the residuals data and the predicted residuals are plotted. The corresponding errors were plotted in Fig. \ref{fig:errors}. Finally, in Fig. \ref{fig:x_pred2}, a final prediction considering both the long term model and the short term model is presented. First, in Figs. \ref{fig:residuals_prediction} and \ref{fig:errors}, it is possible to observe that the predictions of the residuals are closer to the values obtained than the predictions of the energy produced were. This shows that it is valid to consider a model of this form for the short term data. The same can be observed in Figure \ref{fig:x_pred2} when plotting the new predictions of the produced energy and the actually measured produced energy.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/short_term_pred_res.pdf}
    \caption{Residuals and predicted residuals from the short term prediction model.}
    \label{fig:residuals_prediction}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/errors.pdf}
    \caption{Prediction errors corresponding to the previous short term prediction obtained.}
    \label{fig:errors}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/short_term_pred_x.pdf}
    \caption{Training data and prediction considering both long term and short term models.}
    \label{fig:x_pred2}
\end{figure}

\subsection{R1.f) Coefficients and energy of the errors}

In order to obtain the previous predictions, the values of $\hat{\mathbf{d}}$ and the corresponding errors energy were obtained from \texttt{ARmodelR1d.m}. The results were
\begin{equation*}
    \hat{\mathbf{d}} \approx \begin{bmatrix} 0.599 & 0.150 & -0.00308 & 0.273 & -0.1552 & -0.0279 \end{bmatrix}^T, \quad E_e(\hat{\mathbf{d}}) = 0.125.
\end{equation*}
From the value of $\hat{\mathbf{d}}$, it is possible to observe that the most important sample when predicting the next residual is the last one which would be expected. However, it is also important to observe that the importance of the samples is not decreasing. In fact, a sample from an hour before seems to be the second most important. Although it is not understood why, it is relevant to notice this fact. Regarding the value of $E_e(\mathbf{d})$, one must, in the first place, observe that its value is smaller than the value obtained for $E(\hat{a})$, which shows that it is valid to consider this short term model for the residuals. The root mean squared error becomes $RMS = 0.0104$, which has decreased in relation to the long-term prediction result. This is in accordance to what was observed for Fig. \ref{fig:errors}.

\section{R2. Anomaly detection}\label{sec:R2}
\subsection{R2.a) Anomaly detection function}\label{sec:r2a}
The function \texttt{anomalyR2a.m} was developed to detect anomalies in a time series. An anomaly is flagged if the absolute value of the difference between the predicted and given time series is greater than a threshold value. Analyzing the error in the training data, depicted in Fig. \ref{fig:errors}, which does not seem to contain anomalies, the threshold value was chosen to be $t_a = 0.1$.


\subsection{R2.b) Test data prediction and anomaly detection}\label{sec:r2b}
The test data was uploaded and the long-term and short-term prediction were computed, making use of the model found in Section \ref{sec:r1}. Fig. \ref{fig:R2b_test} depicts the comparison of the test data and the long term prediction. Fig. \ref{fig:R2b_residual} depicts the comparison of the test residues and their prediction. 
\begin{figure}[htbp]
	\centering
	\begin{minipage}[b]{.49\textwidth}
		\centering
		\includegraphics[width= 1.1\textwidth]{figures/R2b_test.png}
		\caption{Comparison of test data with long-term prediction.}
		\label{fig:R2b_test}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{.49\textwidth}
		\centering
		\includegraphics[width= 1.1\textwidth]{figures/R2b_residual.png}
		\caption{Comparison of test residues with their  prediction.}
		\label{fig:R2b_residual}
	\end{minipage}
\end{figure}

Evaluating the residue prediction error it is possible to apply the function developed in Section \ref{sec:r2a} to detect anomalies. Fig. \ref{fig:R2b_error_an} depicts the evolution of the residue prediction error and the anomalies identified. The dashed horizontal bars represent the anomaly threshold. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width= 0.8\textwidth]{figures/R2b_error_an.png}
	\caption{Residue prediction error and anomaly identification.}
	\label{fig:R2b_error_an}
\end{figure}

First, it is interesting to analyze the ability of each of the predictions stages with regard to their ability to detect anomalies. Figs. \ref{fig:R2b_test_an} and \ref{fig:R2b_residual_an} depict the prediction of both stages as well as the test data, with the anomalies identified. On one hand, it is possible to notice that it is very difficult to point out the anomalies in the long-term model. For instance, for $n \approx 3590$, the prediction clearly deviates from the test data, and yet, it is not flagged as an anomaly. There are, however, two clear exceptions of isolated points that clearly are outliers, and, thus flagged as an anomaly. On the other hand, it is very clear in the residues prediction that there are several data points that fall out of the regular distribution of data. In this case, the outliers coincide with the flagged anomalies. The short-term model is, thus, able to flag the anomalies more clearly. Second, it is noticeable that the anomalies are identified in pairs of days. Although, it is legitimate that anomalies are flagged in consecutive days, it may well be possible that the long-term prediction of the day after the first anomalies is detected is contaminated with the anomaly of the first day. If this is the case, even thought there is no actual anomaly in the day following the fist anomaly, this contamination leads to falsely flagging an anomaly. This problem is addressed in the following section, so that it is possible to understand if there are, in fact, genuine anomalies in consecutive days or if it is just the effect of the anomaly in the previous day.
\begin{figure}[htbp]
	\centering
	\begin{minipage}[b]{.49\textwidth}
		\centering
		\includegraphics[width= 1.1\textwidth]{figures/R2b_test_an.png}
		\caption{Comparison of test data with long-term prediction with anomaly identification.}
		\label{fig:R2b_test_an}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{.49\textwidth}
		\centering
		\includegraphics[width= 1.1\textwidth]{figures/R2b_residual_an.png}
		\caption{Comparison of test residues with their prediction. with anomaly identification.}
		\label{fig:R2b_residual_an}
	\end{minipage}
\end{figure}

\subsection{R2.c) Data decontamination in the event of an anomaly}
It was pointed pointed out in Section \ref{sec:r2b} that the anomalies are flagged in pair of days. For this reason, in this section it is verified if these are, in fact, genuine anomalies in consecutive days or if it is just the effect of the anomaly in the previous day. There are many ways to attenuate the dependence on the day of the first anomaly on the following days. In this laboratory report two methods are presented: i) one which is more general and suitable to be applied to more complex models than the one at hand; and ii) another which is simpler and is devised for the particular model found in this laboratory.

The first method follows three steps. First, the intervals of time which are, without doubt, contaminated with an anomaly are identified. In this case it was considered that all the data points of the first day in each pair when anomalies are flagged, are contaminated. Fig. \ref{fig:R2c_error_an} shows the data points of the test data which are considered to be, without doubt, contaminated by an anomaly. Again, the horizontal dashed lines in this figure represent the anomaly detection threshold. Second, an iterative procedure is followed so that the test data in the contaminated regions is substituted with data that corresponds to the prediction with the model obtained. For that reason, each iteration is made up of two steps: i) the test data, which was considered to be contaminated, is substituted by the previous prediction; and ii) the test set is predicted again with the previously updated test data set. This iteration is performed until convergence is reached. Third, the predicted data is compared with the original test data set, and the residue prediction error is evaluated with the routine designed in Section \ref{sec:r2a} to identify the anomalies. The anomalies detected in this step are now real anomalies that are not artificially caused by the anomalies identified in the first step. In the code provided these steps are commented carefully and clearly divided. The residue prediction error after these three steps can be seen in Fig. \ref{fig:R2c_error_an_after}. It is very interesting to note that, contrarily to what is seen in the anomaly identification in Fig. \ref{fig:R2b_error_an}, the second anomaly region in each of the three pairs of anomalies is no longer flagged as an anomaly. This confirms the suspicion that the second anomalies being flagged in the previous section were artificially flagged, because of the dependence on the previous day, which was anomalous. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width= 0.8\textwidth]{figures/R2c_error_an.png}
	\caption{Residue prediction error and first anomaly region identification.}
	\label{fig:R2c_error_an}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width= 0.8\textwidth]{figures/R2c_error_an_after.png}
	\caption{Residue prediction error and anomaly identification after the test data is not dependent on the first anomalies found.}
	\label{fig:R2c_error_an_after}
\end{figure}

The second method, is simpler and computationally more efficient, but just because of the simplicity of the long-term prediction. This method follows three steps as well. First, the same first step as in the previous method is followed, identifying the intervals of time which are, without doubt, contaminated with an anomaly. In addition, the test data set in the intervals of time identified as anomalous is substituted by the long-term prevision based on the previous day. Second, the long and short term predictions are computed based on the modified dataset. Third, the residue prediction error is plotted and the test for anomalies is run. Note that, given that the error is relative to the modified dataset, the regions identified in step one, are no longer identified. Fig. \ref{fig:R2c_error_an_after_m2} shows the residue estimation error relative to the modified set. It is noted that there are no regions with anomalies, which is consistent with the result obtained with the first method. It confirms, once again, the suspicion that the second anomalies being flagged in Section \ref{sec:r2b} were artificially flagged because of the dependence on the previous day, which was anomalous. It is also possible to see in this figure that the residue estimation error is null in the regions identified in step one, because is it the error relative to the modified set, which as forced to agree with the long term-prediction of the previous day.

\begin{figure}[htbp]
	\centering
	\includegraphics[width= 0.8\textwidth]{figures/R2c_error_an_after_m2.png}
	\caption{Residue prediction error and anomaly identification after the test data is not dependent on the first anomalies found, using the second method.}
	\label{fig:R2c_error_an_after_m2}
\end{figure}

\end{document}